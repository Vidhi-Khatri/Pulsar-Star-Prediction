{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import seaborn               as sns\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import SVC\n",
    "from xgboost                 import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics         import roc_auc_score\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import precision_score\n",
    "from sklearn.metrics         import recall_score\n",
    "from sklearn.metrics         import f1_score\n",
    "from sklearn.metrics         import balanced_accuracy_score\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from IPython.core.display    import display, HTML\n",
    "from IPython.display         import display_html\n",
    "sns.set(style = \"white\", palette = \"deep\")\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    "\n",
    "1. [Reading In The Data](#Reading-In-The-Data)\n",
    "    - [Overview](#Overview)\n",
    "    \n",
    "    \n",
    "2. [Feature Engineering](#Feature-Engineering)\n",
    "    - [Data Manipulation](#Data-Manipulation)\n",
    "    - [Interaction Columns](#Interaction-Columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar = pd.read_csv(\"../Data/pulsar_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the head of the data\n",
    "\n",
    "pulsar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the data\n",
    "\n",
    "print(f\"The shape of the dataset is: {pulsar.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of column data types\n",
    "\n",
    "pulsar.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "\n",
    "pulsar.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While visualizing the data, we noticed that there are two columns that appeared to have a close to normal distribution.  As a result, we decided to square the values to transform them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squaring the `mean_ip` column\n",
    "\n",
    "pulsar[\"mean_ip_squared\"] = pulsar[\"mean_ip\"].apply(lambda x: x**2)\n",
    "\n",
    "# Squaring the `sd_ip` column\n",
    "\n",
    "pulsar[\"sd_ip_squared\"]   = pulsar[\"sd_ip\"].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of the heat map in the previous notebook, we noticed that there are some columns with very high correlations.  We felt that creating interaction columns, we would be emphasizing the correlation while also reducing the number of features.\n",
    "\n",
    "We defined high correlations as magnitude of >0.5.\n",
    "\n",
    "The columns in particular are:\n",
    "\n",
    "| Column 1   | Column 2   | Correlation |\n",
    "|:-----------|:-----------|:-----------:|\n",
    "| mean_ip    | sd_ip      | 0.55        |\n",
    "| ex_kurt_ip | skew_ip    | 0.95        |\n",
    "| mean_dmsnr | sd_dmsnr   | 0.80        |\n",
    "| ex_kurt_ip | skew_dmsnr | 0.92        |\n",
    "| mean_ip    | ex_kurt_ip | -0.87       |\n",
    "| mean_ip    | skew_ip    | -0.74       |\n",
    "| sd_ip      | ex_kurt_ip | -0.52       |\n",
    "| sd_ip      | skew_ip    | -0.54       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
